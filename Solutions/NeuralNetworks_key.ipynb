{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rx6Y2E_PI1Rg"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCEtYXeKHx1r"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XL6DwYI7I82Z"
   },
   "source": [
    "## Download dataset \n",
    "\n",
    "`transform.compose` allows you to perform more than one transform on the dataset.\n",
    "\n",
    "`transform.ToTensor` converts your data to tensors\n",
    "\n",
    "`transform.Normalize` normalize your data with the mean and standard deviation, this makes the data comparable to each other \n",
    "\n",
    "\n",
    "`trainset` is the training dataset\n",
    "\n",
    "`valset` is the validation dataset \n",
    "\n",
    "the corresponding loaders is used to load the data into the neural network later on, the batch size tells you how many data to load at a time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZwtUCPmIFES"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('drive/My Drive/mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1P7DbueNJ_6k"
   },
   "source": [
    "Below we make the trainloader an iterative type\n",
    "\n",
    "Re-run the cell a few times and see more different examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1565113745268,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "We2U2VMDII8R",
    "outputId": "c0de7a03-6f0a-42b1-88c9-3b095028f13f"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2854,
     "status": "ok",
     "timestamp": 1565113749084,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "YASQV1cJIWK7",
    "outputId": "c6263625-a153-45ae-8cba-dd30f73a4010"
   },
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34H_09TQKZ97"
   },
   "source": [
    "Look at our data and their types.\n",
    "What does the shape values represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1565113750353,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "ZltPvublITsq",
    "outputId": "95d273bc-3caa-4f22-80fa-c2df841fc270"
   },
   "outputs": [],
   "source": [
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPzhdtm-LvFj"
   },
   "source": [
    "## Create a Convolutional Neural Network \n",
    "\n",
    "Look at the example here:\n",
    "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "The architecture to follow for the neural network we are building:\n",
    "\n",
    "ConvNet(\n",
    ">>  (layer1):\n",
    ">>> Sequential(\n",
    "\n",
    ">>> (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "\n",
    ">>> (1): ReLU()\n",
    "\n",
    ">>> (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    ">> )\n",
    "\n",
    ">>  (layer2): \n",
    ">>> Sequential(\n",
    "\n",
    ">>> (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "\n",
    ">>> (1): ReLU()\n",
    "\n",
    ">>>( 2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "\n",
    ">>)\n",
    "\n",
    ">>> (drop_out): Dropout(p=0.5)\n",
    "  \n",
    ">>> (fc1): Linear(in_features=3136, out_features=1000, bias=True)\n",
    "\n",
    ">>> (fc2): Linear(in_features=1000, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PyHWRz8VInFb"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 6\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "from torch import nn\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBGUQjxnNagT"
   },
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSqr8-wlNhGp"
   },
   "source": [
    "Print the model below and check if you created the model with the right architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1565113759051,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "aAWvaPXZNgLG",
    "outputId": "4b48a182-aaf7-49b8-9490-8b4ca92d4c07"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITj6eRIkN8Q5"
   },
   "source": [
    "## Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 347486,
     "status": "ok",
     "timestamp": 1565114783367,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "27N32r06NndG",
    "outputId": "61c55b39-1c17-4a43-98b2-88cedab59495"
   },
   "outputs": [],
   "source": [
    "total_step = len(trainloader)\n",
    "# Keep track of the loss\n",
    "loss_list = []\n",
    "# Keep track of the accuracy\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGepdHZ0OFXS"
   },
   "source": [
    "## Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9654,
     "status": "ok",
     "timestamp": 1565114936486,
     "user": {
      "displayName": "Vivian Gunawan",
      "photoUrl": "",
      "userId": "15085210086296854505"
     },
     "user_tz": 240
    },
    "id": "4KKrwCkTODsE",
    "outputId": "4aa579e9-a45a-44bf-871a-b9126cb72fc2"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in valloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model: {} %'.format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNhDWn9HORbQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jUwIom2OKKi"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(valloader))\n",
    "with torch.no_grad():\n",
    "    # get the prediction by passing in an image to the model\n",
    "    o=model(images)\n",
    "    # Take exponent of this so value is between 0 and 1\n",
    "    ps = torch.exp(o)\n",
    "    ps= ps[0][:]\n",
    "    probab = list(ps.numpy())\n",
    "    # The maximum value in the list is the predicted label of the image\n",
    "    print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "    # To get the probability take this number and divide by the total sum\n",
    "    b=torch.sum(ps)\n",
    "    p=ps/b\n",
    "    # visualize your data\n",
    "    view_classify(images[0].view(1, 28, 28), p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7r5jI067PDVM"
   },
   "source": [
    "## Testing on Air-written Digits\n",
    "\n",
    "Read an image in\n",
    "\n",
    "use `cv2.resize(img, (28,28), interpolation = cv2.INTER_AREA)` to resize your image to match the MNIST data\n",
    "\n",
    "use `cv2.cvtColor` to convert the image to grayscale\n",
    "\n",
    "apply previously defined `transform ` to normalize the image\n",
    "\n",
    "set the image to be viewed the same way by the neural network by calling `view(1,1,28,28)` on the image\n",
    "\n",
    "Use your model to predict the label of your image, use `view_classify` to show your image and the predicted probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6Vt5VeIOSb1"
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5fcrEGPQNlW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNetworks_key.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
